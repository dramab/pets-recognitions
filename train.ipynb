{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.168 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.167  Python-3.9.13 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=E:\\py_code\\pets-recognitions\\dataset, epochs=100, patience=50, batch=8, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=4, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train13\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m E:\\py_code\\pets-recognitions\\dataset\\train... found 21665 images in 76 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m E:\\py_code\\pets-recognitions\\dataset\\val... found 380 images in 76 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=76\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    427596  ultralytics.nn.modules.head.Classify         [256, 76]                     \n",
      "YOLOv8n-cls summary: 99 layers, 1535644 parameters, 1535644 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train13', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\py_code\\pets-recognitions\\dataset\\train... 21659 images, 6 corrupt: 100%|██████████| 21659/21659 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  E:\\py_code\\pets-recognitions\\dataset\\train\\Abyssinian\\Abyssinian_34.jpg: ignoring corrupt image/label: invalid image format GIF\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  E:\\py_code\\pets-recognitions\\dataset\\train\\Egyptian_Mau\\Egyptian_Mau_139.jpg: ignoring corrupt image/label: invalid image format GIF\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  E:\\py_code\\pets-recognitions\\dataset\\train\\Egyptian_Mau\\Egyptian_Mau_145.jpg: ignoring corrupt image/label: invalid image format GIF\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  E:\\py_code\\pets-recognitions\\dataset\\train\\Egyptian_Mau\\Egyptian_Mau_167.jpg: ignoring corrupt image/label: invalid image format GIF\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  E:\\py_code\\pets-recognitions\\dataset\\train\\Egyptian_Mau\\Egyptian_Mau_177.jpg: ignoring corrupt image/label: invalid image format GIF\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  E:\\py_code\\pets-recognitions\\dataset\\train\\Egyptian_Mau\\Egyptian_Mau_191.jpg: ignoring corrupt image/label: invalid image format GIF\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=416, width=416, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\py_code\\pets-recognitions\\dataset\\val... 380 images, 0 corrupt: 100%|██████████| 380/380 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train13\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      1/100     0.837G     0.4386          3        416: 100%|██████████| 2708/2708 [01:26<00:00, 31.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 48.22it/s]\n",
      "                   all      0.297      0.737\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      2/100     0.826G     0.2197          3        416: 100%|██████████| 2708/2708 [01:18<00:00, 34.58it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 44.86it/s]\n",
      "                   all      0.758      0.955\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      3/100     0.826G     0.1237          3        416: 100%|██████████| 2708/2708 [01:16<00:00, 35.47it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 49.52it/s]\n",
      "                   all      0.832      0.979\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      4/100     0.826G    0.09645          3        416: 100%|██████████| 2708/2708 [01:16<00:00, 35.53it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.92it/s]\n",
      "                   all      0.837      0.982\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      5/100     0.826G    0.08027          3        416: 100%|██████████| 2708/2708 [01:15<00:00, 35.64it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 45.79it/s]\n",
      "                   all      0.853      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      6/100     0.826G    0.07146          3        416: 100%|██████████| 2708/2708 [01:15<00:00, 35.75it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.82it/s]\n",
      "                   all      0.861      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      7/100     0.826G    0.06478          3        416: 100%|██████████| 2708/2708 [01:15<00:00, 35.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.05it/s]\n",
      "                   all      0.892      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      8/100     0.826G    0.05918          3        416: 100%|██████████| 2708/2708 [01:18<00:00, 34.31it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.50it/s]\n",
      "                   all      0.876      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "      9/100     0.826G    0.05619          3        416: 100%|██████████| 2708/2708 [01:18<00:00, 34.55it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.84it/s]\n",
      "                   all      0.879      0.997\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     10/100     0.826G    0.05189          3        416: 100%|██████████| 2708/2708 [01:17<00:00, 34.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.95it/s]\n",
      "                   all      0.882      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     11/100     0.826G    0.05021          3        416: 100%|██████████| 2708/2708 [01:17<00:00, 34.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 47.43it/s]\n",
      "                   all      0.905      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     12/100     0.826G    0.04794          3        416: 100%|██████████| 2708/2708 [01:16<00:00, 35.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 50.63it/s]\n",
      "                   all      0.871      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     13/100     0.826G    0.04561          3        416: 100%|██████████| 2708/2708 [01:16<00:00, 35.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 41.82it/s]\n",
      "                   all      0.884      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     14/100     0.826G    0.04342          3        416: 100%|██████████| 2708/2708 [01:17<00:00, 34.99it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 48.27it/s]\n",
      "                   all      0.895      0.995\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     15/100     0.826G    0.04421          3        416: 100%|██████████| 2708/2708 [01:16<00:00, 35.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 48.64it/s]\n",
      "                   all      0.913      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     16/100     0.826G    0.04098          3        416: 100%|██████████| 2708/2708 [01:17<00:00, 35.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 43.55it/s]\n",
      "                   all      0.889      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     17/100     0.826G    0.04137          3        416: 100%|██████████| 2708/2708 [01:18<00:00, 34.34it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 48.77it/s]\n",
      "                   all      0.895      0.987\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     18/100     0.826G    0.03866          3        416: 100%|██████████| 2708/2708 [01:17<00:00, 34.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.08it/s]\n",
      "                   all      0.913      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     19/100     0.826G    0.03839          3        416: 100%|██████████| 2708/2708 [01:17<00:00, 34.88it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.01it/s]\n",
      "                   all      0.911      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     20/100     0.826G    0.03865          3        416: 100%|██████████| 2708/2708 [01:15<00:00, 35.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 42.96it/s]\n",
      "                   all      0.908      0.992\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     21/100     0.826G    0.03532          3        416: 100%|██████████| 2708/2708 [01:17<00:00, 35.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 50.45it/s]\n",
      "                   all      0.913      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     22/100     0.826G    0.03471          3        416: 100%|██████████| 2708/2708 [01:16<00:00, 35.51it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 49.35it/s]\n",
      "                   all      0.913      0.989\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     23/100     0.826G    0.03432          3        416: 100%|██████████| 2708/2708 [01:16<00:00, 35.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 45.97it/s]\n",
      "                   all      0.905      0.995\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     24/100     0.826G    0.03369          3        416: 100%|██████████| 2708/2708 [01:15<00:00, 35.66it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:00<00:00, 46.40it/s]\n",
      "                   all        0.9      0.995\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "     25/100     0.812G    0.03073          8        416:  40%|████      | 1085/2708 [00:31<00:46, 34.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10604\\3348047113.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yolov8n-cls.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr'E:\\py_code\\pets-recognitions\\dataset'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m416\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[1;31m# attach optional HUB session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         \u001b[1;31m# Update model and cfg after training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    358\u001b[0m                 \u001b[1;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mni\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlast_opt_step\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m                     \u001b[0mlast_opt_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mni\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\anaconda3\\lib\\site-packages\\ultralytics\\engine\\trainer.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mema\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\anaconda3\\lib\\site-packages\\ultralytics\\utils\\torch_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    367\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# true for FP16 and FP32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m                     \u001b[0mv\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m                     \u001b[0mv\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmsd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m                     \u001b[1;31m# assert v.dtype == msd[k].dtype == torch.float32, f'{k}: EMA {v.dtype},  model {msd[k].dtype}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n-cls.pt')\n",
    "results = model.train(data=r'E:\\py_code\\pets-recognitions\\dataset', epochs=100,pretrained=True,imgsz=416,workers=4,batch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r'E:\\py_code\\pets-recognitions\\runs\\classify\\train13\\weights\\best.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(resume=True,workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.167  Python-3.9.13 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1532236 parameters, 0 gradients, 3.4 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m E:\\py_code\\pets-recognitions\\dataset\\train... found 21665 images in 76 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m E:\\py_code\\pets-recognitions\\dataset\\val... found 380 images in 76 classes  \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\py_code\\pets-recognitions\\dataset\\val... 380 images, 0 corrupt: 100%|██████████| 380/380 [00:00<?, ?it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|██████████| 24/24 [00:01<00:00, 21.20it/s]\n",
      "                   all      0.913      0.992\n",
      "Speed: 0.5ms preprocess, 1.7ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 E:\\py_code\\pets-recognitions\\test_pic\\.png: 416x416 pembroke 0.61, shiba_inu 0.23, beagle 0.14, chihuahua 0.01, pomeranian 0.00, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001b[1mruns\\classify\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "source = r'E:\\py_code\\pets-recognitions\\test_pic\\柯基.png'\n",
    "results = model(source,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439, 1080, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
